{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-EBk5OJVYKI"
   },
   "source": [
    "# Разработка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIdtS79jVYKO"
   },
   "source": [
    "В этой тетрадке вы должны создать свою модель и сохранить ее веса, чтобы потом их можно было загрузить уже из телеграм бота. Сейчас здесь находится бейзлайн, который вам нужно адаптировать под свой датасет. Идеологически этот проект про ислледовательскую работу, мы хотим, чтобы Вы научились решать задачу классификации с нуля. Поэтому основное время всего проекта должно занять создание модели и ее оптимизация. \n",
    "\n",
    "В качестве фреймворка для всей работы мы предлагаем Вам fast.ai. Эта бибилотека содержит очень много полезных инструментов и проста в освоении. По fast ai есть курс, но он использует устаревшую версию библиотеки, которую нужно устанавливать, копируя папку с гитхаба. Если Вы установили библиотеку через pip, то используйте документацию https://docs.fast.ai/vision.html#vision\n",
    "\n",
    "Список вещей, которые стоит сделать в проекте.  \n",
    "* Подберите лучшую модель\n",
    "* Используте LrFinder\n",
    "* Поберите стратегию для изменения learning rate\n",
    "* Используйте аугментации на обучающем датасете.\n",
    "* Используйте Test Time Augmentation (классфификация по-разному аугментированной картинки и усреднение предсказаний).\n",
    "\n",
    "Не ограничивайтесь этим списком и попытайтесь найти или придумать другие пути для улучшения своей модели, креативность только приветствуется. \n",
    "\n",
    "Во время разработки в этой тетради может содрежаться много разного и несвязного кода, но к концу проекта постарайтесь оформить тетрадку с одной моделью, чтобы другие люди могли использовать вашу работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQ0I09bEVYKU"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from fastai.vision import *\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6Y2tKunVYKg"
   },
   "source": [
    "# В этой части нужно загрузить датасет, разделить его на тренировочную и валидационную выборки и разложить картинки по папкам, чтобы в одной папке лежали картинки одного класса.\n",
    "\n",
    "Эта часть очень сильно зависит от датасета, который вы выбрали, поэтому включить ее в бейзлайн не получится. Если вы выберете датасет, но застрянете на этом шаге, то напишите мне и я помогу разобраться. Это очень важно и не стоит откладывать, так как без приведения датасета к удобному формату вы не сможете продолжить проект."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlN-IFLXVYKi"
   },
   "source": [
    "В моем случае нужно просто загрузить датасет с каггла и распаковать https://www.kaggle.com/joosthazelzet/lego-brick-images/version/1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9221,
     "status": "error",
     "timestamp": 1551076353593,
     "user": {
      "displayName": "Владислав Синеглазов",
      "photoUrl": "",
      "userId": "00098956404814277106"
     },
     "user_tz": -300
    },
    "id": "so0DdAECVYKk",
    "outputId": "feb4fa12-c028-4fd4-c9ba-025dd80b50cb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path('data')\n",
    "data = ImageDataBunch.from_folder(PATH, ds_tfms=get_transforms(), bs=16, size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.load_empty('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-bfaa0ebe4ce5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idxs)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtry_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m   \u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idxs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtry_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxtra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\vision\\data.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;34m\"Subclass if you want to customize how to create item `i` from `self.items`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "type(data.train_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cnn(data=data, arch=models.resnet34, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SwlUHQxqVYKw"
   },
   "source": [
    "# Теперь перейдем к созданию модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKundgfsVYKy",
    "outputId": "d737ebc2-5462-465c-c51f-7e880e260e8c"
   },
   "outputs": [],
   "source": [
    "# если мы создаем предобученную модель, то все слои, кроме последних полносвязных будут заморожены,\n",
    "# стоит помнить об этом при обучении\n",
    "#model = create_cnn(data, models.resnet34, metrics=accuracy, pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "su--KIuvVYK9"
   },
   "source": [
    "# Оставлось обучить модель и проверить ее точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWXxH45GVYLA",
    "outputId": "e07fc53d-1790-4bd7-ef4f-d308b5009c66"
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-61f6f785f4c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Здесь мы используем lr_finder, чтобы выбрать скорость обучения\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\train.py\u001b[0m in \u001b[0;36mlr_find\u001b[1;34m(learn, start_lr, end_lr, num_it, stop_div, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mend_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Здесь мы используем lr_finder, чтобы выбрать скорость обучения\n",
    "model.lr_find()\n",
    "model.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGvO8YfgVYLL",
    "outputId": "a7a68b40-1d33-42af-92c4-930df3bad9d9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPwwqZDfVYLa",
    "outputId": "20d54297-129e-4fbb-e79c-6ec6399e8313"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 03:55 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.139243</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>0.990288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# используем 1cycle policy подрбнее https://docs.fast.ai/callbacks.one_cycle.html\n",
    "model.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REQydKP1VYLm",
    "outputId": "0b5554d0-59f4-4baf-f195-ac2b0a921f09",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace)\n",
       "   (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (6): ReLU(inplace)\n",
       "   (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (11): ReLU(inplace)\n",
       "   (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (16): ReLU(inplace)\n",
       "   (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (19): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (21): ReLU(inplace)\n",
       "   (22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (23): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (24): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   (25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (26): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (27): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (28): ReLU(inplace)\n",
       "   (29): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (30): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (31): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (32): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (33): ReLU(inplace)\n",
       "   (34): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (35): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (36): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (38): ReLU(inplace)\n",
       "   (39): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (40): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), Sequential(\n",
       "   (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace)\n",
       "   (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (5): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (9): ReLU(inplace)\n",
       "   (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (14): ReLU(inplace)\n",
       "   (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (19): ReLU(inplace)\n",
       "   (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (24): ReLU(inplace)\n",
       "   (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (29): ReLU(inplace)\n",
       "   (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (32): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (33): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (34): ReLU(inplace)\n",
       "   (35): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (36): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (37): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (41): ReLU(inplace)\n",
       "   (42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (44): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (46): ReLU(inplace)\n",
       "   (47): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), Sequential(\n",
       "   (0): AdaptiveAvgPool2d(output_size=1)\n",
       "   (1): AdaptiveMaxPool2d(output_size=1)\n",
       "   (2): Lambda()\n",
       "   (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (4): Dropout(p=0.25)\n",
       "   (5): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   (6): ReLU(inplace)\n",
       "   (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (8): Dropout(p=0.5)\n",
       "   (9): Linear(in_features=512, out_features=8, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь мы хотим разморозить всю модель и продолжить finetuning \n",
    "# слои объединены в группы, для каждой группы слоев можно поставить свой learning rate\n",
    "# чтобы узнать, сколько есть групп, выведем их\n",
    "model.layer_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "croZDpI9VYLv",
    "outputId": "3b259720-95b7-4955-eeeb-352e35927451",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 7:41:32 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.134016</td>\n",
       "      <td>0.031519</td>\n",
       "      <td>0.989274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.090561</td>\n",
       "      <td>0.027262</td>\n",
       "      <td>0.991883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.086035</td>\n",
       "      <td>0.021207</td>\n",
       "      <td>0.992898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085336</td>\n",
       "      <td>0.017979</td>\n",
       "      <td>0.992753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.064711</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>0.990723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076467</td>\n",
       "      <td>0.037006</td>\n",
       "      <td>0.987245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072453</td>\n",
       "      <td>0.016674</td>\n",
       "      <td>0.993767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095099</td>\n",
       "      <td>0.018398</td>\n",
       "      <td>0.993912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.085178</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>0.993332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.089988</td>\n",
       "      <td>0.025436</td>\n",
       "      <td>0.990723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.099789</td>\n",
       "      <td>0.041336</td>\n",
       "      <td>0.984201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.120473</td>\n",
       "      <td>0.026718</td>\n",
       "      <td>0.989854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.149465</td>\n",
       "      <td>0.034474</td>\n",
       "      <td>0.988114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.090658</td>\n",
       "      <td>0.024126</td>\n",
       "      <td>0.990433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.114464</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.992318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.992463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.108750</td>\n",
       "      <td>0.021031</td>\n",
       "      <td>0.991593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.128726</td>\n",
       "      <td>0.022943</td>\n",
       "      <td>0.992608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.107541</td>\n",
       "      <td>0.037810</td>\n",
       "      <td>0.987534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.076435</td>\n",
       "      <td>0.156382</td>\n",
       "      <td>0.993332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.141856</td>\n",
       "      <td>0.650238</td>\n",
       "      <td>0.959994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.130288</td>\n",
       "      <td>0.025268</td>\n",
       "      <td>0.990143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.147276</td>\n",
       "      <td>0.720308</td>\n",
       "      <td>0.971735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.106048</td>\n",
       "      <td>0.398941</td>\n",
       "      <td>0.982026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.165626</td>\n",
       "      <td>0.036815</td>\n",
       "      <td>0.985650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.130289</td>\n",
       "      <td>1.267894</td>\n",
       "      <td>0.974199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.072757</td>\n",
       "      <td>0.185573</td>\n",
       "      <td>0.988839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.136640</td>\n",
       "      <td>0.354224</td>\n",
       "      <td>0.988114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.141027</td>\n",
       "      <td>0.173433</td>\n",
       "      <td>0.990578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.101277</td>\n",
       "      <td>0.034867</td>\n",
       "      <td>0.985215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.113043</td>\n",
       "      <td>0.468193</td>\n",
       "      <td>0.989419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.127368</td>\n",
       "      <td>0.026480</td>\n",
       "      <td>0.990723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.606666</td>\n",
       "      <td>0.983766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.090777</td>\n",
       "      <td>0.484055</td>\n",
       "      <td>0.981447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.063774</td>\n",
       "      <td>0.015198</td>\n",
       "      <td>0.994927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.111666</td>\n",
       "      <td>0.111607</td>\n",
       "      <td>0.989999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.084436</td>\n",
       "      <td>0.813772</td>\n",
       "      <td>0.986955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.082454</td>\n",
       "      <td>0.014382</td>\n",
       "      <td>0.996521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.114784</td>\n",
       "      <td>0.167371</td>\n",
       "      <td>0.991738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.084733</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.997391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.055807</td>\n",
       "      <td>0.109154</td>\n",
       "      <td>0.996086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.083216</td>\n",
       "      <td>0.077021</td>\n",
       "      <td>0.996811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.087681</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>0.996811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.054127</td>\n",
       "      <td>1.890230</td>\n",
       "      <td>0.974489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.093728</td>\n",
       "      <td>0.490799</td>\n",
       "      <td>0.988839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.074775</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.998551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.072984</td>\n",
       "      <td>0.022608</td>\n",
       "      <td>0.994347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.068332</td>\n",
       "      <td>0.022783</td>\n",
       "      <td>0.997536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.110799</td>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.997536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.074064</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.997101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.055218</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.997246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.060669</td>\n",
       "      <td>0.037745</td>\n",
       "      <td>0.988984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.053264</td>\n",
       "      <td>0.011119</td>\n",
       "      <td>0.996521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.032263</td>\n",
       "      <td>0.998551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.049501</td>\n",
       "      <td>0.011579</td>\n",
       "      <td>0.997681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.071520</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.998406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.020168</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.998840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.062527</td>\n",
       "      <td>0.056562</td>\n",
       "      <td>0.996666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.047146</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.999855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.035030</td>\n",
       "      <td>0.076321</td>\n",
       "      <td>0.996086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.047266</td>\n",
       "      <td>0.090768</td>\n",
       "      <td>0.996521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.029390</td>\n",
       "      <td>0.013392</td>\n",
       "      <td>0.998261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.051149</td>\n",
       "      <td>0.038199</td>\n",
       "      <td>0.996811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.025691</td>\n",
       "      <td>0.021772</td>\n",
       "      <td>0.999130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.999855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.999275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.010458</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.999130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.999710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.023377</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.024971</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.999130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.011424</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.999565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.025065</td>\n",
       "      <td>0.073202</td>\n",
       "      <td>0.997246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.999855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.017767</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.999710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.999710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.008510</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.999275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.019129</td>\n",
       "      <td>0.998695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.999130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.018439</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.007047</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.unfreeze()\n",
    "# установим learning rate для каждой из трех групп, делать их отличающимися на порядок\n",
    "# хорошая идея в большинстве случаев, при этом lr для последнего слоя мы нашли из lr_find\n",
    "model.fit_one_cycle(100, [1e-4, 1e-3, 1e-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFCLR2jjVYL5"
   },
   "source": [
    "**НЕ ЗАБЫВАЙТЕ, ЧТО ПО УМОЛЧАНИЮ ВСЕ СЛОИ, КРОМЕ ПОСЛЕДНИХ ЗАМОРОЖЕНЫ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = model.data.train_ds[0][0]\n",
    "img = open_image(\"data/valid/car/car_0001.jpg\")\n",
    "pred = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pred[0]\n",
    "probability = np.max(np.array(pred[2]))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car 99.99871253967285\n"
     ]
    }
   ],
   "source": [
    "print(label,probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "seZmWM6UVYL7"
   },
   "source": [
    "# Сохраним веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAAV1HZlVYL9"
   },
   "outputs": [],
   "source": [
    "model.export('trained_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NtE1__VzVYML"
   },
   "source": [
    "В улучшении бейзлайна и получении новых идей Вам сильно поможет документация fast ai. Начать стоит с раздела про vision, а потом посмотреть туториалы, чтобы понимать на что вообще способна библиотека."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gyh3-WjvVYMO"
   },
   "source": [
    "Из интересных идей, которые можно попробовать: можно проводить пару эпох обучения сначала на более маленьких картинках, чем итоговые (тогда при обучении на больших картинках у сети уже будут более менее неплохие веса). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W58QggriVYMR",
    "outputId": "756efb3f-6ae6-44cc-850a-4c80e453c382"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-2d8dd321fe19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[1;34m'LabelList'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: shape"
     ]
    }
   ],
   "source": [
    "data.train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1P7mvbHwVYMb"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ModelResearch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
